{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9193100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm for time series forecasting\n",
    "from numpy import sqrt, asarray\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from tensorflow import keras, math, reduce_mean\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, BatchNormalization\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ab386",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 5\n",
    "SET_SIZE = 19\n",
    "TEST_PROPORTION = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps=5):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        # filter this properly\n",
    "        # TODO: training on an irregular matrix\n",
    "        seq_x, seq_y = sequence[i:end_ix+1, :], sequence[end_ix, -1]\n",
    "        seq_x[-1, -1] = 0\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = read_csv(\"./Solar Forecasting/SolarTrainingData.csv\", index_col=0)\n",
    "\n",
    "df = df.drop(['year', 'day'], axis=1)\n",
    "df.tail()\n",
    "randstart = random.randint(0, df.size/SET_SIZE-N_STEPS)\n",
    "df_predictor = asarray(df.iloc[randstart:randstart+N_STEPS+1]).reshape(1, N_STEPS+1, SET_SIZE)\n",
    "dataframeset = [df.iloc[:randstart], df.iloc[randstart+N_STEPS+1:]]\n",
    "df = pd.concat(dataframeset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b609ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the values\n",
    "values = df.values.astype('float32')\n",
    "# specify the window size\n",
    "# split into samples\n",
    "X, y = split_sequence(values, N_STEPS)\n",
    "# reshape into [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))\n",
    "# split into train/test\n",
    "n_test = int(X.shape[0]/TEST_PROPORTION)\n",
    "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# TODO: figure out how to set up the batchnormalization layer to be at the start, without normalizing percent output\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(N_STEPS+1,len(df.iloc[0]))))\n",
    "# LSTM to weight recency\n",
    "model.add(LSTM(100, activation='relu', kernel_initializer='he_normal'))\n",
    "# dense layers to regenerate spatiality\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(25, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=2, validation_data=(X_test, y_test), callbacks=[callback])\n",
    "# evaluate the model\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d404d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "print(randstart)\n",
    "actual_result = df_predictor[-1, -1, -1]\n",
    "print('Real: %.3f' % (actual_result))\n",
    "df_predictor[-1, -1, -1] = 0\n",
    "print(df_predictor)\n",
    "yhat = model.predict(df_predictor)\n",
    "print('Predicted: %.3f' % (yhat))\n",
    "acc = 100 - abs((actual_result - yhat) / actual_result * 100)\n",
    "print('Accuracy: %.3f' % (acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
